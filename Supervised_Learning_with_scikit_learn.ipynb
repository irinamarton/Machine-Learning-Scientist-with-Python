{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wb7yt16BBzxH",
        "ns20Y3BKB3vR",
        "keUNvSbqCAGL",
        "cLLDnJqbDrbK",
        "Xx1Y3vPTFlSj",
        "mCdrdeT2GZYY",
        "VHDfsnI5U8Gk",
        "1s_yKyOZXfSJ",
        "0e2X0OXHYmtL",
        "UHSNp3KAarIc",
        "R9Z-PLbDbIIK",
        "d_6ImVqVby0T",
        "JYif-7CCcGIM",
        "LjIyyLF8dWWm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "SB1KtGQu_blC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###k-Nearest Neighbors: Fit"
      ],
      "metadata": {
        "id": "wb7yt16BBzxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will build your first classification model using the `churn_df` dataset, which has been preloaded for the remainder of the chapter.\n",
        "\n",
        "The features to use will be `\"account_length\"` and `\"customer_service_calls\"`. The target, `\"churn\"`, needs to be a single column with the same number of observations as the feature data.\n",
        "\n",
        "You will convert the features and the target variable into NumPy arrays, create an instance of a KNN classifier, and then fit it to the data.\n",
        "\n",
        "`numpy` has also been preloaded for you as `np`.\n",
        "\n",
        "> Instructions\n",
        "> *   Import `KNeighborsClassifier` from `sklearn.neighbors`.\n",
        "*   Create an array called `X` containing values from the `\"account_length\"` and `\"customer_service_calls\"` columns, and an array called `y` for the values of the `\"churn\"` column.\n",
        "*   Instantiate a `KNeighborsClassifier` called `knn` with `6` neighbors.\n",
        "*   Fit the classifier to the data using the `.fit()` method.\n"
      ],
      "metadata": {
        "id": "uVCaDx_G_pRX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bG8q5pLz_aAP"
      },
      "outputs": [],
      "source": [
        "# Import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "\n",
        "# Create arrays for the features and the target variable\n",
        "y = churn_df[\"churn\"].values\n",
        "X = churn_df[[\"account_length\", \"customer_service_calls\"]].values\n",
        "\n",
        "# Create a KNN classifier with 6 neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Fit the classifier to the data\n",
        "knn.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###k-Nearest Neighbors: Predict"
      ],
      "metadata": {
        "id": "ns20Y3BKB3vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have fit a KNN classifier, you can use it to predict the label of new data points. All available data was used for training, however, fortunately, there are new observations available. These have been preloaded for you as `X_new`.\n",
        "\n",
        "The model `knn`, which you created and fit the data in the last exercise, has been preloaded for you. You will use your classifier to predict the labels of a set of new data points:\n",
        "\n",
        "\n",
        "```\n",
        "X_new = np.array([[30.0, 17.5],\n",
        "                  [107.0, 24.1],\n",
        "                  [213.0, 10.9]])\n",
        "```\n",
        "\n",
        "\n",
        "> Instructions\n",
        "*   Create `y_pred` by predicting the target values of the unseen features `X_new`.\n",
        "*   Print the predicted labels for the set of predictions."
      ],
      "metadata": {
        "id": "Zo-DZYt0An0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels for the X_new\n",
        "y_pred = knn.predict(X_new)\n",
        "\n",
        "# Print the predictions for X_new\n",
        "print(\"Predictions: {}\".format(y_pred)) "
      ],
      "metadata": {
        "id": "VYjGXTR3BZvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train/test split + computing accuracy"
      ],
      "metadata": {
        "id": "keUNvSbqCAGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have learned about the importance of splitting your data into training and test sets, it's time to practice doing this on the `churn_df` dataset!\n",
        "\n",
        "NumPy arrays have been created for you containing the features as `X` and the target variable as `y`. You will split them into training and test sets, fit a KNN classifier to the training data, and then compute its accuracy on the test data using the `.score()` method.\n",
        "\n",
        "\n",
        "\n",
        "> Instructions\n",
        "*   Import `train_test_split` from `sklearn.model_selection`.\n",
        "*   Split `X` and `y` into training and test sets, setting `test_size` equal to 20%, `random_state` to `42`, and ensuring the target label proportions reflect that of the original dataset.\n",
        "*   Fit the `knn` model to the training data.\n",
        "*   Compute and print the model's accuracy for the test data"
      ],
      "metadata": {
        "id": "pAAcC5RFCGRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = churn_df.drop(\"churn\", axis=1).values\n",
        "y = churn_df[\"churn\"].values\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Print the accuracy\n",
        "print(knn.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "c16ZHuqCC5mX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overfitting and underfitting"
      ],
      "metadata": {
        "id": "cLLDnJqbDrbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreting model complexity is a great way to evaluate performance when utilizing supervised learning. Your aim is to produce a model that can interpret the relationship between features and the target variable, as well as generalize well when exposed to new observations.\n",
        "\n",
        "You will generate accuracy scores for the training and test sets using a KNN classifier with different `n_neighbor` values, which you will plot in the next exercise.\n",
        "\n",
        "The training and test sets have been created from the `churn_df` dataset and preloaded as `X_train`, `X_test`, `y_train`, and `y_test`.\n",
        "\n",
        "In addition, `KNeighborsClassifier` has been imported for you along with `numpy` as `np`.\n",
        "\n",
        "\n",
        "> Instructions\n",
        "*   Create `neighbors` as a `numpy` array of values from `1` up to and including `12`.\n",
        "*   Instantiate a KNN classifier, with the number of neighbors equal to the `neighbor` iterator.\n",
        "*   Fit the model to the training data.\n",
        "* Calculate accuracy scores for the training set and test set separately using the `.score()` method, and assign the results to the index of the `train_accuracies` and `test_accuracies` dictionaries, respectively."
      ],
      "metadata": {
        "id": "amg6FgH7DtZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create neighbors\n",
        "neighbors = np.arange(1, 13)\n",
        "train_accuracies = {}\n",
        "test_accuracies = {}\n",
        "\n",
        "for neighbor in neighbors:\n",
        "  \n",
        "\t# Set up a KNN Classifier\n",
        "\tknn = KNeighborsClassifier(n_neighbors=neighbor)\n",
        "  \n",
        "\t# Fit the model\n",
        "\tknn.fit(X_train, y_train)\n",
        "  \n",
        "\t# Compute accuracy\n",
        "\ttrain_accuracies[neighbor] = knn.score(X_train, y_train)\n",
        "\ttest_accuracies[neighbor] = knn.score(X_test, y_test)\n",
        "print(neighbors, '\\n', train_accuracies, '\\n', test_accuracies)"
      ],
      "metadata": {
        "id": "p4oshHC3EPTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing model complexity"
      ],
      "metadata": {
        "id": "Xx1Y3vPTFlSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have calculated the accuracy of the KNN model on the training and test sets using various values of `n_neighbors`, you can create a model complexity curve to visualize how performance changes as the model becomes less complex!\n",
        "\n",
        "The variables `neighbors`, `train_accuracies`, and `test_accuracies`, which you generated in the previous exercise, have all been preloaded for you. You will plot the results to aid in finding the optimal number of neighbors for your model.\n",
        "\n",
        "> Instructions\n",
        "* Add a title `\"KNN: Varying Number of Neighbors\"`.\n",
        "* Plot the `.values()` method of `train_accuracies` on the y-axis against `neighbors` on the x-axis, with a label of `\"Training Accuracy\"`.\n",
        "* Plot the `.values()` method of `test_accuracies` on the y-axis against `neighbors` on the x-axis, with a label of `\"Testing Accuracy\"`.\n",
        "* Display the plot."
      ],
      "metadata": {
        "id": "2473RqYpFonT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a title\n",
        "plt.title(\"KNN: Varying Number of Neighbors\")\n",
        "\n",
        "# Plot training accuracies\n",
        "plt.plot(neighbors, train_accuracies.values(), label=\"Training Accuracy\")\n",
        "\n",
        "# Plot test accuracies\n",
        "plt.plot(neighbors, test_accuracies.values(), label=\"Testing Accuracy\")\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"Number of Neighbors\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQh7rQHbGOco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Regression"
      ],
      "metadata": {
        "id": "x8G_r3TvGWuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating features\n"
      ],
      "metadata": {
        "id": "mCdrdeT2GZYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter, you will work with a dataset called `sales_df`, which contains information on advertising campaign expenditure across different media types, and the number of dollars generated in sales for the respective campaign. The dataset has been preloaded for you. Here are the first two rows:\n",
        "\n",
        "```\n",
        "     tv        radio      social_media    sales\n",
        "1    13000.0   9237.76    2409.57         46677.90\n",
        "2    41000.0   15886.45   2913.41         150177.83\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You will use the advertising expenditure as features to predict sales values, initially working with the `\"radio\"` column. However, before you make any predictions you will need to create the feature and target arrays, reshaping them to the correct format for scikit-learn.\n",
        "\n",
        "> Instructions\n",
        "* Create `X`, an array of the values from the `sales_df` DataFrame's `\"radio\"` column.\n",
        "* Create `y`, an array of the values from the `sales_df` DataFrame's `\"sales\"` column.\n",
        "* Reshape `X` into a two-dimensional NumPy array.\n",
        "* Print the shape of `X` and `y`."
      ],
      "metadata": {
        "id": "4r_2AdjgUbXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create X from the radio column's values\n",
        "X = sales_df[\"radio\"].values\n",
        "\n",
        "# Create y from the sales column's values\n",
        "y =sales_df[\"sales\"].values\n",
        "\n",
        "# Reshape X\n",
        "X = X.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of the features and targets\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "jZQNzimRU2k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a linear regression model"
      ],
      "metadata": {
        "id": "VHDfsnI5U8Gk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have created your feature and target arrays, you will train a linear regression model on all feature and target values.\n",
        "\n",
        "As the goal is to assess the relationship between the feature and target values there is no need to split the data into training and test sets.\n",
        "\n",
        "`X` and `y` have been preloaded for you as follows:\n",
        "\n",
        "\n",
        "```\n",
        "y = sales_df[\"sales\"].values\n",
        "X = sales_df[\"radio\"].values.reshape(-1, 1)\n",
        "```\n",
        "\n",
        "\n",
        ">Instructions\n",
        "* Import `LinearRegression`.\n",
        "* Instantiate a linear regression model.\n",
        "* Predict sales values using `X`, storing as `predictions`."
      ],
      "metadata": {
        "id": "ksjUkj2UU-GL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LinearRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create the model\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = reg.predict(X)\n",
        "\n",
        "print(predictions[:5])"
      ],
      "metadata": {
        "id": "Dc_4CUOEWL6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing a linear regression model"
      ],
      "metadata": {
        "id": "1s_yKyOZXfSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have built your linear regression model and trained it using all available observations, you can visualize how well the model fits the data. This allows you to interpret the relationship between `radio` advertising expenditure and `sales` values.\n",
        "\n",
        "The variables `X`, an array of `radio` values, `y`, an array of `sales` values, and `predictions`, an array of the model's predicted values for `y` given `X`, have all been preloaded for you from the previous exercise.\n",
        "\n",
        ">Instructions\n",
        "* Import `matplotlib.pyplot` as `plt`.\n",
        "* Create a scatter plot visualizing `y` against `X`, with observations in blue.\n",
        "* Draw a red line plot displaying the predictions against `X`.\n",
        "* Display the plot."
      ],
      "metadata": {
        "id": "P6TA2-99XjkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import matplotlib.pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(X, y, color=\"blue\")\n",
        "\n",
        "# Create line plot\n",
        "plt.plot(X, predictions, color=\"red\")\n",
        "plt.xlabel(\"Radio Expenditure ($)\")\n",
        "plt.ylabel(\"Sales ($)\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tzLJ1qdRX_tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit and predict for regression"
      ],
      "metadata": {
        "id": "0e2X0OXHYmtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have seen how linear regression works, your task is to create a multiple linear regression model using all of the features in the `sales_df` dataset, which has been preloaded for you. As a reminder, here are the first two rows:\n",
        "\n",
        "\n",
        "```\n",
        "     tv        radio      social_media    sales\n",
        "1    13000.0   9237.76    2409.57         46677.90\n",
        "2    41000.0   15886.45   2913.41         150177.83\n",
        "```\n",
        "\n",
        "\n",
        "You will then use this model to predict sales based on the values of the test features.\n",
        "\n",
        "`LinearRegression` and `train_test_split` have been preloaded for you from their respective modules.\n",
        "\n",
        "> Instructions\n",
        "* Create `X`, an array containing values of all features in `sales_df`, and `y`, containing all values from the `\"sales\"` column.\n",
        "* Instantiate a linear regression model.\n",
        "* Fit the model to the training data.\n",
        "* Create `y_pred`, making predictions for `sales` using the test features."
      ],
      "metadata": {
        "id": "34fqecBLY06S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y arrays\n",
        "X = sales_df.drop(\"sales\", axis=1).values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Instantiate the model\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.predict(X_test)\n",
        "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
      ],
      "metadata": {
        "id": "49YDsCOCaDM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression performance"
      ],
      "metadata": {
        "id": "UHSNp3KAarIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have fit a model, `reg`, using all features from `sales_df`, and made predictions of sales values, you can evaluate performance using some common regression metrics.\n",
        "\n",
        "The variables `X_train`, `X_test`, `y_train`, `y_test`, and `y_pred`, along with the fitted model, `reg`, all from the last exercise, have been preloaded for you.\n",
        "\n",
        "Your task is to find out how well the features can explain the variance in the target values, along with assessing the model's ability to make predictions on unseen data.\n",
        "\n",
        "> Instructions\n",
        "* Import `mean_squared_error`.\n",
        "* Calculate the model's R-squared score by passing the test feature values and the test target values to an appropriate method.\n",
        "* Calculate the model's root mean squared error using `y_test` and `y_pred`.\n",
        "* Print `r_squared` and `rmse`."
      ],
      "metadata": {
        "id": "RVqT4oWRau6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Compute R-squared\n",
        "r_squared = reg.score(X_test, y_test)\n",
        "\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"R^2: {}\".format(r_squared))\n",
        "print(\"RMSE: {}\".format(rmse))"
      ],
      "metadata": {
        "id": "5C4Y80pYbFSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-validation for R-squared"
      ],
      "metadata": {
        "id": "R9Z-PLbDbIIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-validation is a vital approach to evaluating a model. It maximizes the amount of data that is available to the model, as the model is not only trained but also tested on all of the available data.\n",
        "\n",
        "In this exercise, you will build a linear regression model, then use 6-fold cross-validation to assess its accuracy for predicting sales using social media advertising expenditure. You will display the individual score for each of the six-folds.\n",
        "\n",
        "The `sales_df` dataset has been split into `y` for the target variable, and `X` for the features, and preloaded for you. `LinearRegression` has been imported from `sklearn.linear_model`.\n",
        "\n",
        "> Instructions\n",
        "* Import `KFold` and `cross_val_score`.\n",
        "* Create `kf` by calling `KFold()`, setting the number of splits to six, `shuffle` to `True`, and setting a seed of `5`.\n",
        "* Perform cross-validation using `reg` on `X` and `y`, passing `kf` to `cv`.\n",
        "* Print the `cv_scores`."
      ],
      "metadata": {
        "id": "piwpQJjObPdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Create a KFold object\n",
        "kf = KFold(n_splits=6, shuffle=True, random_state=5)\n",
        "\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Compute 6-fold cross-validation scores\n",
        "cv_scores = cross_val_score(reg, X, y, cv=kf)\n",
        "\n",
        "# Print scores\n",
        "print(cv_scores)"
      ],
      "metadata": {
        "id": "mBMX0HYybssY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing cross-validation metrics"
      ],
      "metadata": {
        "id": "d_6ImVqVby0T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have performed cross-validation, it's time to analyze the results.\n",
        "\n",
        "You will display the mean, standard deviation, and 95% confidence interval for `cv_results`, which has been preloaded for you from the previous exercise.\n",
        "\n",
        "`numpy` has been imported for you as `np`.\n",
        "\n",
        "> Instructions\n",
        "* Calculate and print the mean of the results.\n",
        "* Calculate and print the standard deviation of cv_results.\n",
        "* Display the 95% confidence interval for your results using np.quantile()."
      ],
      "metadata": {
        "id": "Il0snG4Cb0nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the mean\n",
        "print(np.mean(cv_results))\n",
        "\n",
        "# Print the standard deviation\n",
        "print(np.std(cv_results))\n",
        "\n",
        "# Print the 95% confidence interval\n",
        "print(np.quantile(cv_results, [0.025, 0.975]))"
      ],
      "metadata": {
        "id": "PagaJ4R_cA3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regularized regression: Ridge"
      ],
      "metadata": {
        "id": "JYif-7CCcGIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression performs regularization by computing the *squared* values of the model parameters multiplied by alpha and adding them to the loss function.\n",
        "\n",
        "In this exercise, you will fit ridge regression models over a range of different alpha values, and print their R^2 scores. You will use all of the features in the `sales_df` dataset to predict `\"sales\"`. The data has been split into `X_train`, `X_test`, `y_train`, `y_test` for you.\n",
        "\n",
        "A variable called `alphas` has been provided as a list containing different alpha values, which you will loop through to generate scores.\n",
        "\n",
        "> Instructions\n",
        "* Import `Ridge`.\n",
        "* Instantiate `Ridge`, setting alpha equal to `alpha`.\n",
        "* Fit the model to the training data.\n",
        "* Calculate the R^2 score for each iteration of `ridge`."
      ],
      "metadata": {
        "id": "PZX6EGS-cObd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Ridge\n",
        "from sklearn.linear_model import Ridge\n",
        "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
        "ridge_scores = []\n",
        "for alpha in alphas:\n",
        "  \n",
        "  # Create a Ridge regression model\n",
        "  ridge = Ridge(alpha=alpha)\n",
        "  \n",
        "  # Fit the data\n",
        "  ridge.fit(X_train, y_train)\n",
        "  \n",
        "  # Obtain R-squared\n",
        "  score = ridge.score(X_test, y_test)\n",
        "  ridge_scores.append(score)\n",
        "print(ridge_scores)"
      ],
      "metadata": {
        "id": "32VHAMtTdXO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lasso regression for feature importance"
      ],
      "metadata": {
        "id": "LjIyyLF8dWWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the video, you saw how lasso regression can be used to identify important features in a dataset.\n",
        "\n",
        "In this exercise, you will fit a lasso regression model to the `sales_df` data and plot the model's coefficients.\n",
        "\n",
        "The feature and target variable arrays have been pre-loaded as `X` and `y`, along with `sales_columns`, which contains the dataset's feature names.\n",
        "\n",
        "> Instructions\n",
        "* Import `Lasso` from `sklearn.linear_model`.\n",
        "* Instantiate a Lasso regressor with an alpha of `0.3`.\n",
        "* Fit the model to the data.\n",
        "* Compute the model's coefficients, storing as `lasso_coef`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jWAklT5XdtDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lasso\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "# Instantiate a lasso regression model\n",
        "lasso = Lasso(alpha=0.3)\n",
        "\n",
        "# Fit the model to the data\n",
        "lasso.fit(X, y)\n",
        "\n",
        "# Compute and print the coefficients\n",
        "lasso_coef = lasso.coef_\n",
        "print(lasso_coef)\n",
        "plt.bar(sales_columns, lasso_coef)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Relhf_O9eGFQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}